{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80c18325",
   "metadata": {},
   "source": [
    "# Basic end to end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f3ebd",
   "metadata": {},
   "source": [
    "- Look at the big picture\n",
    "- Get the data\n",
    "- Explore and visualize the data to gain insights\n",
    "- Prepare the data for machine learning algorithms\n",
    "- Select a model and train it. \n",
    "- Fine-tune the model\n",
    "- Present your solution\n",
    "- Launch, monitor and maintain your system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e79da7",
   "metadata": {},
   "source": [
    "## Task\n",
    "model the california housing dataest, and predict the median housing price in any district given all the other metrics.\n",
    "\n",
    "The task at hand is a multiple regression, univariate. \n",
    "since there is not continuous flow of data coming into the system, there is not particular need to adjust to changing data rapidly. and data is small enough to fit in memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d83fceb",
   "metadata": {},
   "source": [
    "### pipeline\n",
    "\n",
    "A sequence of data processing componetns is called a data pipeline. \n",
    "piepelines are vary common in ML systems\n",
    "\n",
    "components typically run asynchronously. Each component pulls in a large amount of data, processes it, and spits out the result in another data store. \n",
    "\n",
    "each component is fairly self-contained. the interface is only the data store. no other information is passed, so seperation of concerns is well-maintained. \n",
    "\n",
    "This seperation of concerns makes the system simpel to grasp. Different teams can focus on different components, and if a component breaks down the downstream components can continue to run normally for a while\n",
    "\n",
    "Thus, pipelines are quite robust. \n",
    "\n",
    "However, if a borken component goes down, the component can go unnoticed for some time if proper monitoring is not implemented. teh data goes stale and the performance drops. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09694d",
   "metadata": {},
   "source": [
    "### selecting a performance measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18511d8b",
   "metadata": {},
   "source": [
    "RMSE is generally used as a performance measure for regression tasks. \n",
    "in some contexts, where there many outliers, mean absolute error is more helpful. \n",
    "\n",
    "rmse corresponds to euclidean norm\n",
    "mae corresponds to l1 norm (manhattan norm)\n",
    "\n",
    "the higher the norm index, the more it focuses on large values, and neglects small values. Thus, rmse is more sensitive to outlisers than the mae. but when outliers are rare, the rmse performs very well. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be436343",
   "metadata": {},
   "source": [
    "## downlaoding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486db561",
   "metadata": {},
   "source": [
    "In typical environments, data would be available in a relational database, or some other data store. \n",
    "Now however, the data store is publicly available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b74af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ad4509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b8/cky_62q57zxch2nprk7rqs0m0000gn/T/ipykernel_4415/573949084.py:8: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  housing_tarball.extractall(path = 'datasets')\n"
     ]
    }
   ],
   "source": [
    "def load_housing_data():\n",
    "    tarball_path = Path(\"datasets/housing.tgz\")\n",
    "    if not tarball_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents = True, exist_ok = True)\n",
    "        url = \"https://github.com/ageron/data/raw/main/housing.tgz\"\n",
    "        urllib.request.urlretrieve(url, tarball_path)\n",
    "        with tarfile.open(tarball_path) as housing_tarball:\n",
    "            housing_tarball.extractall(path = 'datasets')\n",
    "    \n",
    "    return pd.read_csv(Path(\"datasets/housing/housing.csv\"))\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0b76a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
